{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe91160-02ad-48cc-810b-1031f21397ff",
   "metadata": {},
   "source": [
    "# Image Classification with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea01e6-2184-4d88-a9e3-c05f70953f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83163df1-5732-459b-948a-b88d07d692cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4067288c-39ac-4f51-a5b3-f3a043f0c3a9",
   "metadata": {},
   "source": [
    "### Load and re-scale input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55daa661-47bb-4499-b8a4-dce7f5cadc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf93aa8-eaa0-4143-84fc-2c617d402bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.FashionMNIST('./data', train=True, download=True, transform=transformer)\n",
    "test_dataset = datasets.FashionMNIST('./data', train=False, transform=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2574d6-659d-4ef5-92a5-ffbe7036dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_dataset.data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30236f-5707-4517-9b6e-3eeb0601500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {v: k for k, v in train_dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b7f58e-291e-4084-933e-4e3357fe42fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(test_dataset[i][0][0])\n",
    "    plt.title(classes[test_dataset[i][1]])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef148e96-02d9-45d2-825d-01951a45f047",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60570c8d-b61d-4558-8d3d-e831279e898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbed0a8-9d1c-49b1-9e41-59d15b2e134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2d6f1-9db7-43d7-b00c-b44e5eba8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8880f-47a3-4b0f-8fee-be0f4b8a0b85",
   "metadata": {},
   "source": [
    "### Train the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c04fcb-4769-4022-ab84-89ee2412febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b9446-9820-416a-8bd2-96b8712c33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "accuracy = MulticlassAccuracy(num_classes=len(train_dataset.classes))\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')                        \n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    for inputs, labels in testloader:\n",
    "        preds = model(inputs)\n",
    "        print(f\"Accuracy on validation set: {float(accuracy(preds, labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e22f40-9f03-4b89-8233-5306d7a4061b",
   "metadata": {},
   "source": [
    "### Classification beyond fully connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8519786-c1bc-4bd3-b3dd-09fca96928d8",
   "metadata": {},
   "source": [
    "For a slightly more complex and deeper network, try to train the model below that uses Convolution Neural Network (CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7e5b5-ceac-4d3b-bd61-1c3274d090d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(CNNModel, self).__init__() \n",
    "        # 1 input channel (grayscale), 32 output filters \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3) \n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Pooling with a 2x2 window \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3) \n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 64) \n",
    "        # 64 filters output, 5x5 feature map  \n",
    " \n",
    "        self.fc2 = nn.Linear(64, 10)  # 10 output classes \n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.pool(F.relu(self.conv1(x)))   \n",
    "        x = self.pool(F.relu(self.conv2(x))) \n",
    "        x = x.view(-1, 64 * 5 * 5) \n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.fc2(x) \n",
    "        return F.log_softmax(x, dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110e26e-73a2-42ef-8146-880e05656778",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44762dd1-fcbf-4e9a-bfdf-f55d284bf78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76b705-2b7f-45c4-99c8-32984d239af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "accuracy = MulticlassAccuracy(num_classes=len(train_dataset.classes))\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')                        \n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    for inputs, labels in testloader:\n",
    "        preds = model(inputs)\n",
    "        print(f\"Accuracy on validation set: {float(accuracy(preds, labels))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b2cef-831a-4efe-83b3-f3125a9cd439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chap3",
   "language": "python",
   "name": "chap3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
