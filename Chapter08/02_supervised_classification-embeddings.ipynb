{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow-Learning Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will show you how to create a topic model, using a shallow-learning approach. Here we will use the results and the embeddings obtained from the document-document projection of the bipartite graph.\n",
    "\n",
    "**NOTE: This Notebook can only be run after the 01_nlp_graph_creation notebook, as some of the results computed in the first notebook will be here reused.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_pickle(\"corpus.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "topics = Counter([label for document_labels in corpus[\"label\"] for label in document_labels]).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('earn', 3964),\n",
       " ('acq', 2369),\n",
       " ('money-fx', 717),\n",
       " ('grain', 582),\n",
       " ('crude', 578),\n",
       " ('trade', 485),\n",
       " ('interest', 478),\n",
       " ('ship', 286),\n",
       " ('wheat', 283),\n",
       " ('corn', 237)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicsList = [topic[0] for topic in topics]\n",
    "topicsSet = set(topicsList)\n",
    "dataset = corpus[corpus[\"label\"].apply(lambda x: len(topicsSet.intersection(x))>0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class to \"simulate\" the training of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class EmbeddingsTransformer(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, embeddings_file):\n",
    "        self.embeddings_file = embeddings_file\n",
    "        \n",
    "    def fit(self, *args, **kwargs):\n",
    "        self.embeddings = pd.read_pickle(self.embeddings_file)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self.embeddings.loc[X.index]\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        return self.fit().transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "files = glob(\"./embeddings/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphEmbeddings = EmbeddingsTransformer(files[0]).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(corpus, topicsList=topicsList):\n",
    "    return corpus[\"label\"].apply(\n",
    "        lambda labels: pd.Series({label: 1 for label in labels}).reindex(topicsList).fillna(0)\n",
    "    )[topicsList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(corpus):\n",
    "    return corpus[\"parsed\"] #graphEmbeddings.transform(corpus[\"parsed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(corpus):\n",
    "    return get_features(corpus), get_labels(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(corpus):\n",
    "    graphIndex = [index for index in corpus.index if index in graphEmbeddings.embeddings.index]\n",
    "    \n",
    "    train_idx = [idx for idx in graphIndex if \"training/\" in idx]\n",
    "    test_idx = [idx for idx in graphIndex if \"test/\" in idx]\n",
    "    return corpus.loc[train_idx], corpus.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model and cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputClassifier(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"embeddings\", graphEmbeddings),\n",
    "    (\"model\", model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./embeddings/bipartiteGraphEmbeddings_10_20.p']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"embeddings__embeddings_file\": files,\n",
    "    \"model__estimator__n_estimators\": [50, 100], \n",
    "    \"model__estimator__max_features\": [0.2,0.3, \"auto\"], \n",
    "    #\"model__estimator__max_depth\": [3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = get_features_and_labels(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=-1, \n",
    "                           scoring=lambda y_true, y_pred: f1_score(y_true, y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deusebio/.pyenv/versions/graph-machine-learning/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/home/deusebio/.pyenv/versions/graph-machine-learning/lib/python3.8/site-packages/sklearn/model_selection/_search.py:931: RuntimeWarning: invalid value encountered in cast\n",
      "  results[\"rank_%s\" % key_name] = np.asarray(\n"
     ]
    }
   ],
   "source": [
    "model = grid_search.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('embeddings',\n",
       "                                        EmbeddingsTransformer(embeddings_file='./embeddings/bipartiteGraphEmbeddings_10_20.p')),\n",
       "                                       ('model',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'embeddings__embeddings_file': ['./embeddings/bipartiteGraphEmbeddings_10_20.p'],\n",
       "                         'model__estimator__max_features': [0.2, 0.3, 'auto'],\n",
       "                         'model__estimator__n_estimators': [50, 100]},\n",
       "             scoring=<function <lambda> at 0x7f5fd7adf3a0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings__embeddings_file': './embeddings/bipartiteGraphEmbeddings_10_20.p',\n",
       " 'model__estimator__max_features': 0.2,\n",
       " 'model__estimator__n_estimators': 50}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, features):\n",
    "    return pd.DataFrame(\n",
    "        model.predict(features), \n",
    "        columns=topicsList, \n",
    "        index=features.index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_predictions(model, get_features(test))\n",
    "labels = get_labels(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = 1 - (labels - preds).abs().sum().sum() / labels.abs().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7072120559741657"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1087\n",
      "           1       0.94      0.83      0.88       719\n",
      "           2       0.77      0.67      0.72       179\n",
      "           3       0.93      0.71      0.81       149\n",
      "           4       0.89      0.67      0.76       189\n",
      "           5       0.83      0.43      0.56       117\n",
      "           6       0.79      0.44      0.56       131\n",
      "           7       0.88      0.33      0.48        89\n",
      "           8       0.76      0.44      0.55        71\n",
      "           9       0.61      0.20      0.30        56\n",
      "\n",
      "   micro avg       0.92      0.77      0.84      2787\n",
      "   macro avg       0.84      0.56      0.66      2787\n",
      "weighted avg       0.91      0.77      0.83      2787\n",
      " samples avg       0.81      0.80      0.80      2787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deusebio/.pyenv/versions/graph-machine-learning/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chap8",
   "language": "python",
   "name": "chap8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
