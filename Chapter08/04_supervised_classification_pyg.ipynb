{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Network Topic Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will focus on building a model for topic classification based on a Graph Neural Network approach.\n",
    "\n",
    "In particular in the following we will show you how to:\n",
    "\n",
    "* Create a TF-IDF representation of the corpus, that will be used as node features in the Graph Neural Network model \n",
    "* Build, train a Graph Neural Network model and identify the best threshold for classifying documents \n",
    "\n",
    "**NOTE: This Notebook can only be run after the 01_nlp_graph_creation notebook, as some of the results computed in the first notebook will be here reused.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_pickle(\"corpus.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "topics = Counter([label for document_labels in corpus[\"label\"] for label in document_labels]).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicsList = [topic[0] for topic in topics]\n",
    "topicsSet = set(topicsList)\n",
    "dataset = corpus[corpus[\"label\"].apply(lambda x: len(topicsSet.intersection(x))>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(corpus, topicsList=topicsList):\n",
    "    return corpus[\"label\"].apply(\n",
    "        lambda labels: pd.Series({label: 1 for label in labels}).reindex(topicsList).fillna(0)\n",
    "    )[topicsList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_labels(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(corpus):\n",
    "    return corpus[\"parsed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(corpus):\n",
    "    return get_features(corpus), get_labels(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(corpus):\n",
    "    train_idx = [idx for idx in corpus.index if \"training/\" in idx]\n",
    "    test_idx = [idx for idx in corpus.index if \"test/\" in idx]\n",
    "    return corpus.loc[train_idx], corpus.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_spacy_tokenizer(pos_filter=[\"NOUN\", \"VERB\", \"PROPN\"]):\n",
    "    def tokenizer(doc):\n",
    "        return [token.lemma_ for token in doc if (pos_filter is None) or (token.pos_ in pos_filter)] \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntVectorizer = TfidfVectorizer(\n",
    "    analyzer=my_spacy_tokenizer(),\n",
    "    max_df = 0.25, min_df = 2, max_features = 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeatures, _ = get_features_and_labels(train)\n",
    "testFeatures, _ = get_features_and_labels(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedTransformed = cntVectorizer.fit_transform(trainFeatures)\n",
    "testTransformed = cntVectorizer.transform(testFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([\n",
    "    pd.DataFrame.sparse.from_spmatrix(trainedTransformed, index=trainFeatures.index), \n",
    "    pd.DataFrame.sparse.from_spmatrix(testTransformed, index=testFeatures.index)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_pickle(\"bipartiteEdges.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entityTypes = {entity: ith for ith, entity in enumerate(edges[\"type\"].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entityTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentFeatures = features.loc[list(set(corpus.index).intersection(features.index))] #.assign(document=1, entity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = edges.groupby([\"target\", \"type\"])[\"source\"].count().groupby(level=0).apply(\n",
    "    lambda s: s.droplevel(0).reindex(entityTypes.keys()).fillna(0)\n",
    ").unstack(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entityFeatures = (entities.T / entities.sum(axis=1)).T.assign(document=0, entity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {\"entity\": entityFeatures, \n",
    "         \"document\": documentFeatures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = labels.reindex(documentFeatures.index).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(corpus):\n",
    "    graphIndex = [index for index in corpus.index]\n",
    "    \n",
    "    train_idx = [idx for idx in graphIndex if \"training/\" in idx]\n",
    "    test_idx = [idx for idx in graphIndex if \"test/\" in idx]\n",
    "    return corpus.loc[train_idx], corpus.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled, hold_out = train_test_split(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, leftOut = train_test_split(\n",
    "    sampled,\n",
    "    train_size=0.1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "validation, test = train_test_split(\n",
    "    leftOut, train_size=0.2, test_size=None, random_state=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.sum(axis=1) > 0]\n",
    "validation = validation[validation.sum(axis=1) > 0]\n",
    "test = test[test.sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train: {train.shape}\")\n",
    "print(f\"Validation: {validation.shape}\")\n",
    "print(f\"Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_maps = {k: ith for ith, k in enumerate(documentFeatures.index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_maps = {k: ith for ith, k in enumerate(entityFeatures.index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_maps = {k: ith for ith, k in enumerate(labels.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[\"source_id\"] = edges[\"source\"].apply(lambda x: docs_maps.get(x, -1))\n",
    "edges[\"target_id\"] = edges[\"target\"].apply(lambda x: ents_maps.get(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_sparse\n",
    "\n",
    "def df_to_torch(df: pd.DataFrame):\n",
    "    try:\n",
    "        # @amarzullo: needs to be torch_sparse coo\n",
    "        coo = df.sparse_to_coo()\n",
    "        return torch_sparse.coalesce(coo.coords, coo.data, coo.shape)\n",
    "        #coo = df.sparse.to_coo()\n",
    "        #return torch.sparse_coo_tensor(coo.coords, coo.data, coo.shape) #.to_sparse_csr()\n",
    "    except AttributeError:\n",
    "        return torch.from_numpy(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "data[\"document\"].x = df_to_torch(documentFeatures)#.to_dense() #@amarzullo to_dense\n",
    "data[\"entity\"].x = df_to_torch(entityFeatures)#.to_dense() #@amarzullo to_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _type, group in edges[(edges[\"source_id\"]!=-1) * (edges[\"target_id\"]!=-1)].groupby(\"type\"):\n",
    "    data[(\"document\", _type, \"entity\")].edge_index = df_to_torch(group[[\"source_id\", \"target_id\"]].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"document\"].y = df_to_torch(targets).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"document\"][\"train_mask\"] = df_to_torch(train.sum(axis=1).reindex(documentFeatures.index).fillna(0)).to(torch.bool)\n",
    "data[\"document\"][\"val_mask\"] = df_to_torch(validation.sum(axis=1).reindex(documentFeatures.index).fillna(0)).to(torch.bool)\n",
    "data[\"document\"][\"test_mask\"] = df_to_torch(test.sum(axis=1).reindex(documentFeatures.index).fillna(0)).to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = x.float() #@amarzullo\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "\n",
    "model = GNN(hidden_channels=64, out_channels=len(labs_maps))\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out = model(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Accuracy:\n",
    "    correct: int\n",
    "    total: int\n",
    "\n",
    "    @property\n",
    "    def score(self):\n",
    "        return float(self.correct) * 1.0 / self.total\n",
    "\n",
    "    def __add__(self, other: 'Accuracy'):\n",
    "        if not isinstance(other, Accuracy):\n",
    "            raise ValueError(\"Cannot add objects other than Accuracy\")\n",
    "\n",
    "        return Accuracy(self.correct+other.correct, self.total+other.total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(correct):\n",
    "    return Accuracy(int(correct.sum()), int(np.prod(correct.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(data, train_mask):\n",
    "    model.train()\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "        \n",
    "    loss = F.binary_cross_entropy(out['document'][train_mask], data['document'].y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval(data, mask):\n",
    "     # Test/Evaluate\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x_dict, data.edge_index_dict)[\"document\"][mask]\n",
    "\n",
    "    pred = (1.0*(out>0.5) == data[\"document\"].y[mask])\n",
    "    \n",
    "    return score(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = data['document'].train_mask\n",
    "val_mask = data['document'].val_mask\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    loss = training(data, train_mask)\n",
    "        \n",
    "    # Test/Evaluate\n",
    "    train_score, val_score = eval(data, train_mask), eval(data, val_mask)\n",
    "\n",
    "    print(f\"Epoch {epoch} => Training: {train_score.score} Validation: {val_score.score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_nodes = ('document', data['document'].train_mask)\n",
    "val_input_nodes = ('document', data['document'].val_mask)\n",
    "kwargs = {'batch_size': 128}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborLoader(data, num_neighbors=[10] * 2, shuffle=True,\n",
    "                                  input_nodes=train_input_nodes, **kwargs)\n",
    "val_loader = NeighborLoader(data, num_neighbors=[10] * 2,\n",
    "                                input_nodes=val_input_nodes, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = Accuracy(0, 0)\n",
    "for nth, batch in enumerate(train_loader):\n",
    "    batch_size = batch['document'].batch_size\n",
    "    train_mask = range(batch_size)\n",
    "    train_score += eval(batch, train_mask)\n",
    "\n",
    "val_score = Accuracy(0, 0)\n",
    "for nth, batch in enumerate(val_loader):\n",
    "    batch_size = batch['document'].batch_size\n",
    "    train_mask = range(batch_size)\n",
    "    val_score += eval(batch, train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    loss = 0\n",
    "    for nth, batch in enumerate(train_loader):\n",
    "        batch_size = batch['document'].batch_size\n",
    "        train_mask = range(batch_size)\n",
    "        loss += training(batch, train_mask)*batch_size\n",
    "\n",
    "    # Training error\n",
    "    train_score = Accuracy(0, 0)\n",
    "    for nth, batch in enumerate(train_loader):\n",
    "        batch_size = batch['document'].batch_size\n",
    "        train_mask = range(batch_size)\n",
    "        train_score += eval(batch, train_mask)\n",
    "\n",
    "    val_score = Accuracy(0, 0)\n",
    "    for nth, batch in enumerate(val_loader):\n",
    "        batch_size = batch['document'].batch_size\n",
    "        train_mask = range(batch_size)\n",
    "        val_score += eval(batch, train_mask)\n",
    "    \n",
    "    print(f\"Epoch {epoch} => Loss: {loss} Train: {train_score.score} Val: {val_score.score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_nodes = ('document', data['document'].test_mask)\n",
    "kwargs = {'batch_size': 128}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = NeighborLoader(data, num_neighbors=[10] * 2, input_nodes=test_input_nodes, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_output(data, mask):\n",
    "     # Test/Evaluate\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x_dict, data.edge_index_dict)[\"document\"][mask]\n",
    "\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "def reindex(df, indices):\n",
    "    df.index = indices\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_index(df, docs_maps, labs_maps):\n",
    "    inv_docs_maps = {v:k for k, v in docs_maps.items()}\n",
    "    inv_labs_maps = {v:k for k, v in labs_maps.items()}\n",
    "    \n",
    "    df.index = [inv_docs_maps[x] for x in df.index]\n",
    "    df.columns = [inv_labs_maps[x] for x in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for nth, batch in enumerate(test_loader):\n",
    "    batch_size = batch['document'].batch_size\n",
    "    train_mask = range(batch_size)\n",
    "    preds.append(\n",
    "        remap_index(\n",
    "            reindex(\n",
    "                get_output(batch, train_mask), \n",
    "                batch[\"document\"].input_id.tolist()\n",
    "            ),\n",
    "            docs_maps,\n",
    "            labs_maps\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.concat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.concat({\n",
    "    \"target\": test, \n",
    "    \"preds\": test_predictions\n",
    "}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = {}\n",
    "\n",
    "for th in [0.01,0.05,0.1,0.2,0.3,0.4,0.5]:\n",
    "    f1s[th] = f1_score(test_results[\"target\"], 1.0*(test_results[\"preds\"]>th), average=\"macro\")\n",
    "    \n",
    "pd.Series(f1s).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_results[\"target\"], 1.0*(test_results[\"preds\"]>0.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chap8",
   "language": "python",
   "name": "chap8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
